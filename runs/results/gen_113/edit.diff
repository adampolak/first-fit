--- a/original.py
+++ b/original.py
@@ -1,242 +1,310 @@
 # EVOLVE-BLOCK-START
 
 from math import gcd
 from functools import reduce
 
 def overlaps(a, b):
     """Open-interval overlap test: return True iff intervals overlap."""
     (l1, r1), (l2, r2) = a, b
     return max(l1, l2) < min(r1, r2)
 
 def firstfit_colors(intervals):
     """
     Simulate FirstFit coloring on the given arrival order.
     Return total number of colors used.
     """
     colors = []  # list of color classes; each is a list of intervals in arrival order
     for iv in intervals:
         placed = False
         for c in colors:
             conflict = False
             # Check conflict within this color class (pairwise disjoint invariant holds,
             # but we conservatively check all to stay robust)
             for u in c:
                 if overlaps(u, iv):
                     conflict = True
                     break
             if not conflict:
                 c.append(iv)
                 placed = True
                 break
         if not placed:
             colors.append([iv])
     return len(colors)
 
 def clique_number(intervals):
     """
     Compute omega (maximum number of intervals covering a single point) using sweep.
     For open intervals, endpoints do not contribute to overlap.
     """
     events = []  # (x, type) where type=-1 for right endpoint, +1 for left endpoint
     for (l, r) in intervals:
         if l >= r:
             continue
         events.append((l, +1))
         events.append((r, -1))
     # For open intervals, at the same coordinate handle -1 before +1
     events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
     cur = 0
     best = 0
     for _, t in events:
         cur += t
         if cur > best:
             best = cur
     return best
 
 def make_copies(T, offsets, delta, lo, center, translation):
     """
     Create 4 translated copies of T according to offsets and translation rule.
     translation in {'left', 'center'}.
     """
     S = []
     for start in offsets:
         if translation == 'left':
             offset = delta * start - lo
         else:  # center-based
             offset = delta * start - center
         for (l, r) in T:
             S.append((l + offset, r + offset))
     return S
 
 def add_blockers(S, blockers, delta, anchor, center):
     """
     Add 4 blockers scaled by delta. Anchor may be 'left' (absolute) or 'center' (center-shifted).
     """
     for (a, b) in blockers:
         if anchor == 'left':
             S.append((delta * a, delta * b))
         else:
             S.append((delta * a - center, delta * b - center))
     return S
 
 def build_pattern(k, base_seed, offsets, blockers, translation, blocker_anchor):
     """
     Recursively expand the base_seed k times using the 4-copy + 4-blocker scheme.
     """
     T = list(base_seed)
     for _ in range(k):
         lo = min(l for l, r in T)
         hi = max(r for l, r in T)
         delta = hi - lo
         center = (lo + hi) / 2.0
 
         S = []
         S = make_copies(T, offsets, delta, lo, center, translation)
         S = add_blockers(S, blockers, delta, blocker_anchor, center)
 
         T = S
     return T
 
 def normalize_intervals(intervals):
     """
     Normalize to small integer coordinates:
     - scale by 2 to eliminate .5 if produced by center shifts
     - translate so min coordinate is >= 0
     - (optional) divide by global gcd to shrink
     """
     if not intervals:
         return intervals
     # scale by 2 and round (the construction only yields multiples of 0.5)
     scaled = []
     for (l, r) in intervals:
         L = int(round(l * 2))
         R = int(round(r * 2))
         scaled.append((L, R))
     min_coord = min(min(l, r) for l, r in scaled)
     shifted = [(l - min_coord, r - min_coord) for (l, r) in scaled]
     # Keep integers modestâ€”divide by gcd of all endpoints if possible
     vals = []
     for (l, r) in shifted:
         vals.append(abs(l))
         vals.append(abs(r))
     g = 0
     for v in vals:
         g = gcd(g, v)
     if g > 1:
         shrunk = [(l // g, r // g) for (l, r) in shifted]
     else:
         shrunk = shifted
     return shrunk
 
 def evaluate(intervals):
     """
     Compute FF colors and omega, with a small penalty for ridiculously large outputs.
     Return (score, omega, num_colors, n, intervals_normalized)
     """
     Tn = normalize_intervals(intervals)
     n = len(Tn)
     if n == 0:
         return (-1.0, 0, 0, n, Tn)
     om = clique_number(Tn)
     if om == 0:
         return (-1.0, 0, 0, n, Tn)
     cols = firstfit_colors(Tn)
     ratio = cols / om
     # soft penalty to prefer smaller n when ratios tie
     score = ratio - 1e-6 * (n / 10000.0)
     return (score, om, cols, n, Tn)
 
 def construct_intervals():
     """
     Build a sequence of open intervals that aims to maximize FirstFit/OPT.
     We sweep several recommended blueprints and pick the best validated candidate.
     """
     # search space inspired by the provided recommendations
     offsets_set = [
         (2, 6, 10, 14),  # baseline
         (1, 5, 9, 13),
         (3, 7, 11, 15),
         (0, 4, 8, 12),
     ]
     blockers_templates = [
         # Template A: baseline
         ((1, 5), (12, 16), (4, 9), (8, 13)),
         # Template B
         ((0, 4), (6, 10), (8, 12), (14, 18)),
         # Template C
         ((2, 6), (4, 8), (10, 14), (12, 16)),
     ]
     translations = ['left', 'center']  # how copies are positioned
     blocker_anchors = ['left', 'center']  # how blockers are positioned
     depths = [3, 4, 5]  # sweep as recommended
     base_seeds = [
         [(0.0, 1.0)],                      # single seed (classic)
         [(0.0, 1.0), (2.0, 3.0)],          # richer base: two disjoint seeds
     ]
 
     best = None  # (score, om, cols, n, intervals)
     # Enumerate combinations with a guard on worst-case explosion
     for base in base_seeds:
         for k in depths:
             # Hard cap: avoid extremely large instances in the inner evaluator
             # expected size ~ 4^k * |base| + O(4^k)
             if (4 ** k) * (len(base) + 2) > 2000:
                 continue
             for offsets in offsets_set:
                 for blockers in blockers_templates:
                     for translation in translations:
                         for anchor in blocker_anchors:
                             T = build_pattern(
                                 k=k,
                                 base_seed=base,
                                 offsets=offsets,
                                 blockers=blockers,
                                 translation=translation,
                                 blocker_anchor=anchor,
                             )
                             score, om, cols, n, Tn = evaluate(T)
 
                             cand = (score, om, cols, n, Tn)
                             if best is None:
                                 best = cand
                             else:
                                 # pick better score; tie-break by fewer intervals then larger cols
                                 if cand[0] > best[0] + 1e-9:
                                     best = cand
                                 elif abs(cand[0] - best[0]) <= 1e-9:
                                     if cand[3] < best[3]:
                                         best = cand
                                     elif cand[3] == best[3] and cand[2] > best[2]:
                                         best = cand
 
     # Fallback to baseline if search didn't produce anything
     if best is None:
         # original baseline as a safe default
         k = 4
         T = [(0.0, 1.0)]
         for _ in range(k):
             lo = min(l for l, r in T)
             hi = max(r for l, r in T)
             delta = hi - lo
             S = []
             for start in (2, 6, 10, 14):
                 offset = delta * start - lo
                 for (l, r) in T:
                     S.append((l + offset, r + offset))
             S += [
                 (delta * 1,  delta * 5),
                 (delta * 12, delta * 16),
                 (delta * 4,  delta * 9),
                 (delta * 8,  delta * 13),
             ]
             T = S
         return normalize_intervals(T)
 
-    # Return the best found normalized intervals
-    return best[4]
+    # Return the best found normalized intervals, but first apply a
+    # deterministic greedy adversarial reordering to (often) increase
+    # FirstFit color usage without changing the geometry (omega).
+    #
+    # Greedy rule:
+    #  - maintain color_last_end array representing the right endpoint of the
+    #    last interval placed into each current color class;
+    #  - at each step, for every remaining interval compute the color index
+    #    FirstFit would assign it given color_last_end (the first color i with
+    #    interval.left >= color_last_end[i], or new color len(color_last_end));
+    #  - pick an interval that maximizes this assigned index (tie-break by
+    #    longest length then leftmost).
+    base_norm = best[4]
+
+    def greedy_worst_order(intervals):
+        remaining = list(intervals)
+        order = []
+        # color_last_end stores the current right endpoint for each color class
+        color_last_end = []
+
+        # compute assigned index quickly
+        def assigned_index(iv):
+            l, r = iv
+            for i, le in enumerate(color_last_end):
+                # open intervals: can place in color i if l >= last_end
+                if l >= le:
+                    return i
+            return len(color_last_end)
+
+        while remaining:
+            # compute assigned indices for all remaining intervals and pick best
+            best_idx = -1
+            best_cands = []
+            for iv in remaining:
+                idx = assigned_index(iv)
+                if idx > best_idx:
+                    best_idx = idx
+                    best_cands = [iv]
+                elif idx == best_idx:
+                    best_cands.append(iv)
+            # tie-break among candidates: prefer longest interval, then leftmost
+            if len(best_cands) == 1:
+                pick = best_cands[0]
+            else:
+                pick = max(best_cands, key=lambda x: ((x[1] - x[0]), -x[0]))
+            # assign pick into color_last_end (simulate FirstFit placement)
+            placed = False
+            l, r = pick
+            for i, le in enumerate(color_last_end):
+                if l >= le:
+                    color_last_end[i] = r
+                    placed = True
+                    break
+            if not placed:
+                color_last_end.append(r)
+            order.append(pick)
+            remaining.remove(pick)
+        return order
+
+    # Apply greedy reordering and return it (already normalized coordinates)
+    try:
+        reordered = greedy_worst_order(base_norm)
+        # sanity: ensure omega unchanged (geometry unchanged so should be same)
+        # but if something odd happens, fall back to base_norm
+        if reordered and len(reordered) == len(base_norm):
+            return reordered
+        else:
+            return base_norm
+    except Exception:
+        return base_norm
 
 # EVOLVE-BLOCK-END
 
 def run_experiment(**kwargs):
   """Main called by evaluator"""
   return construct_intervals()