--- a/original.py
+++ b/original.py
@@ -1,251 +1,170 @@
 # EVOLVE-BLOCK-START
 
 from math import gcd
-from functools import reduce
-
-def overlaps(a, b):
-    """Open-interval overlap test: return True iff intervals overlap."""
-    (l1, r1), (l2, r2) = a, b
-    return max(l1, l2) < min(r1, r2)
+# Basic overlap, FirstFit and clique routines
+def overlaps(a,b):
+    (l1,r1),(l2,r2)=a,b
+    return max(l1,l2)<min(r1,r2)
 
 def firstfit_colors(intervals):
-    """
-    Simulate FirstFit coloring on the given arrival order.
-    Return total number of colors used.
-    """
-    colors = []  # list of color classes; each is a list of intervals in arrival order
-    for iv in intervals:
-        placed = False
-        for c in colors:
-            conflict = False
-            # Check conflict within this color class (pairwise disjoint invariant holds,
-            # but we conservatively check all to stay robust)
-            for u in c:
-                if overlaps(u, iv):
-                    conflict = True
-                    break
-            if not conflict:
-                c.append(iv)
-                placed = True
+    last_end=[]
+    for l,r in intervals:
+        placed=False
+        for i,le in enumerate(last_end):
+            if l>=le:
+                last_end[i]=r
+                placed=True
                 break
         if not placed:
-            colors.append([iv])
-    return len(colors)
+            last_end.append(r)
+    return len(last_end)
 
 def clique_number(intervals):
-    """
-    Compute omega (maximum number of intervals covering a single point) using sweep.
-    For open intervals, endpoints do not contribute to overlap.
-    """
-    events = []  # (x, type) where type=-1 for right endpoint, +1 for left endpoint
-    for (l, r) in intervals:
-        if l >= r:
-            continue
-        events.append((l, +1))
-        events.append((r, -1))
-    # For open intervals, at the same coordinate handle -1 before +1
-    events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
-    cur = 0
-    best = 0
-    for _, t in events:
-        cur += t
-        if cur > best:
-            best = cur
+    events=[]
+    for l,r in intervals:
+        if l<r:
+            events.append((l,1)); events.append((r,-1))
+    events.sort(key=lambda e:(e[0],e[1]))
+    cur=best=0
+    for _,d in events:
+        cur+=d
+        if cur>best: best=cur
     return best
 
-def make_copies(T, offsets, delta, lo, center, translation):
-    """
-    Create 4 translated copies of T according to offsets and translation rule.
-    translation in {'left', 'center'}.
-    """
-    S = []
-    for start in offsets:
-        if translation == 'left':
-            offset = delta * start - lo
-        else:  # center-based
-            offset = delta * start - center
-        for (l, r) in T:
-            S.append((l + offset, r + offset))
-    return S
-
-def add_blockers(S, blockers, delta, anchor, center):
-    """
-    Add 4 blockers scaled by delta. Anchor may be 'left' (absolute) or 'center' (center-shifted).
-    """
-    for (a, b) in blockers:
-        if anchor == 'left':
-            S.append((delta * a, delta * b))
-        else:
-            S.append((delta * a - center, delta * b - center))
-    return S
-
-def build_pattern(k, base_seed, offsets, blockers, translation, blocker_anchor):
-    """
-    Recursively expand the base_seed k times using the 4-copy + 4-blocker scheme.
-    """
-    T = list(base_seed)
-    for _ in range(k):
-        lo = min(l for l, r in T)
-        hi = max(r for l, r in T)
-        delta = hi - lo
-        center = (lo + hi) / 2.0
-
-        S = []
-        S = make_copies(T, offsets, delta, lo, center, translation)
-        S = add_blockers(S, blockers, delta, blocker_anchor, center)
-
-        T = S
+# Two‐stage pruning
+def prune_stage1(T, tc, to):
+    changed=True
+    while changed:
+        changed=False
+        # try removing longest intervals first
+        for i,iv in sorted(enumerate(T), key=lambda x:-(x[1][1]-x[1][0])):
+            U=T[:i]+T[i+1:]
+            if firstfit_colors(U)==tc and clique_number(U)==to:
+                T=U; changed=True; break
     return T
 
-def normalize_intervals(intervals):
-    """
-    Normalize to small integer coordinates:
-    - scale by 2 to eliminate .5 if produced by center shifts
-    - translate so min coordinate is >= 0
-    - (optional) divide by global gcd to shrink
-    """
-    if not intervals:
-        return intervals
-    # scale by 2 and round (the construction only yields multiples of 0.5)
-    scaled = []
-    for (l, r) in intervals:
-        L = int(round(l * 2))
-        R = int(round(r * 2))
-        scaled.append((L, R))
-    min_coord = min(min(l, r) for l, r in scaled)
-    shifted = [(l - min_coord, r - min_coord) for (l, r) in scaled]
-    # Keep integers modest—divide by gcd of all endpoints if possible
-    vals = []
-    for (l, r) in shifted:
-        vals.append(abs(l))
-        vals.append(abs(r))
-    g = 0
-    for v in vals:
-        g = gcd(g, v)
-    if g > 1:
-        shrunk = [(l // g, r // g) for (l, r) in shifted]
-    else:
-        shrunk = shifted
-    return shrunk
+def prune_stage2(T, tc, to):
+    # find a witness point for ω
+    events=[]
+    for l,r in T:
+        events.append((l,1)); events.append((r,-1))
+    events.sort(key=lambda e:(e[0],e[1]))
+    cur=best=0; wp=events[0][0]
+    for x,d in events:
+        cur+=d
+        if cur>best:
+            best=cur; wp=x
+    cover={i for i,(l,r) in enumerate(T) if l<wp<r}
+    changed=True
+    while changed:
+        changed=False
+        for i,iv in sorted(enumerate(T), key=lambda x:-(x[1][1]-x[1][0])):
+            if i in cover: continue
+            U=T[:i]+T[i+1:]
+            if firstfit_colors(U)==tc and clique_number(U)==to:
+                T=U; changed=True; break
+    return T
 
-def evaluate(intervals):
-    """
-    Compute FF colors and omega, with a small penalty for ridiculously large outputs.
-    Return (score, omega, num_colors, n, intervals_normalized)
-    """
-    Tn = normalize_intervals(intervals)
-    n = len(Tn)
-    if n == 0:
-        return (-1.0, 0, 0, n, Tn)
-    om = clique_number(Tn)
-    if om == 0:
-        return (-1.0, 0, 0, n, Tn)
-    cols = firstfit_colors(Tn)
-    ratio = cols / om
-    # soft penalty to prefer smaller n when ratios tie
-    score = ratio - 1e-6 * (n / 10000.0)
-    return (score, om, cols, n, Tn)
+def normalize(T):
+    if not T: return []
+    pts=sorted({x for seg in T for x in seg})
+    mp={v:i*2 for i,v in enumerate(pts)}
+    L=[(mp[l],mp[r]) for l,r in T]
+    mn=min(l for l,_ in L)
+    L=[(l-mn,r-mn) for l,r in L]
+    g=0
+    for a,b in L:
+        g=gcd(g,abs(a)); g=gcd(g,abs(b))
+    if g>1:
+        L=[(a//g,b//g) for a,b in L]
+    return L
+
+# Wave templates
+SHORT_WAVE=[(1,3),(3,5),(5,7)]
+LONG_WAVE=[(8,12),(12,16),(16,20)]
+# Four tiling patterns
+TILING=[(2,6,10,14),(1,5,9,13),(3,7,11,15),(0,4,8,12)]
+# Memoization cache
+_eval_cache={}
+
+def evaluate_cached(intervals):
+    key=tuple(normalize(intervals))
+    if key in _eval_cache:
+        return _eval_cache[key]
+    Tn=normalize(intervals)
+    om=clique_number(Tn)
+    cols=firstfit_colors(Tn)
+    score=cols/om - 1e-6*(len(Tn)/10000.0)
+    _eval_cache[key]=(score,om,cols,len(Tn),Tn)
+    return _eval_cache[key]
+
+def build_pattern(base, depth, blockers, translation, anchor, wave_type, eps):
+    T=list(base)
+    for lvl in range(depth):
+        lo=min(l for l,r in T); hi=max(r for l,r in T)
+        d=hi-lo; c=(lo+hi)/2.0
+        # cycle tiling with perturbation
+        offs=[s+eps for s in TILING[lvl%4]]
+        S=[]
+        for s in offs:
+            off = (d*s - lo) if translation=='left' else (d*s - c)
+            for l,r in T:
+                S.append((l+off,r+off))
+        # blockers
+        for a,b in blockers:
+            if anchor=='left':
+                S.append((d*(a+eps),d*(b+eps)))
+            else:
+                S.append((d*(a+eps)-c,d*(b+eps)-c))
+        # wave augmentation every other level
+        wave = SHORT_WAVE if wave_type=='short' else LONG_WAVE
+        if lvl%2==0:
+            for a,b in wave:
+                S.append((d*a,d*b))
+        T=S
+    return T
 
 def construct_intervals():
-    """
-    Build a sequence of open intervals that aims to maximize FirstFit/OPT.
-    We sweep several recommended blueprints and pick the best validated candidate.
-    """
-    # search space inspired by the provided recommendations
-    offsets_set = [
-        (2, 6, 10, 14),  # baseline
-        (1, 5, 9, 13),
-        (3, 7, 11, 15),
-        (0, 4, 8, 12),
-    ]
-    blockers_templates = [
-        # Template A: baseline
-        ((1, 5), (12, 16), (4, 9), (8, 13)),
-        # Template B
-        ((0, 4), (6, 10), (8, 12), (14, 18)),
-        # Template C
-        ((2, 6), (4, 8), (10, 14), (12, 16)),
-    ]
-    translations = ['left', 'center']  # how copies are positioned
-    blocker_anchors = ['left', 'center']  # how blockers are positioned
-    depths = [3, 4, 5]  # sweep as recommended
-    base_seeds = [
-        [(0.0, 1.0)],                      # single seed (classic)
-        [(0.0, 1.0), (2.0, 3.0)],          # richer base: two disjoint seeds
-    ]
-    extra_copies_opts = [0, 1, 2]  # allow up to two extra copies on first level
+    base_seeds=[[(0.0,1.0)],[(0.0,1.0),(2.0,3.0)]]
+    blockers_set=[((1,5),(12,16),(4,9),(8,13)), ((0,4),(6,10),(8,12),(14,18))]
+    translations=['left','center']
+    anchors=['left','center']
+    wave_types=['short','long']
+    epsilons=[-0.1,0.0,0.1]
+    depths=[3,4,5,6]
 
-    best = None  # (score, om, cols, n, intervals)
-    # Enumerate combinations with a guard on worst-case explosion
+    best=None
     for base in base_seeds:
-        for k in depths:
-            # Hard cap: avoid extremely large instances in the inner evaluator
-            # expected size ~ 4^k * |base| + O(4^k)
-            if (4 ** k) * (len(base) + 4) > 2000:
-                continue
-            for offsets in offsets_set:
-                for extra in extra_copies_opts:
-                    # build potentially extended offsets list
-                    offs = list(offsets)
-                    if extra >= 1:
-                        offs.append(offsets[-1] + 4)
-                    if extra >= 2:
-                        offs.append(offsets[-1] + 8)
-                    offs = tuple(offs)
-                    for blockers in blockers_templates:
-                        for translation in translations:
-                            for anchor in blocker_anchors:
-                                T = build_pattern(
-                                    k=k,
-                                    base_seed=base,
-                                    offsets=offs,
-                                    blockers=blockers,
-                                    translation=translation,
-                                    blocker_anchor=anchor,
-                                )
-                                score, om, cols, n, Tn = evaluate(T)
-
-                            cand = (score, om, cols, n, Tn)
-                            if best is None:
-                                best = cand
-                            else:
-                                # pick better score; tie-break by fewer intervals then larger cols
-                                if cand[0] > best[0] + 1e-9:
-                                    best = cand
-                                elif abs(cand[0] - best[0]) <= 1e-9:
-                                    if cand[3] < best[3]:
-                                        best = cand
-                                    elif cand[3] == best[3] and cand[2] > best[2]:
-                                        best = cand
-
-    # Fallback to baseline if search didn't produce anything
-    if best is None:
-        # original baseline as a safe default
-        k = 4
-        T = [(0.0, 1.0)]
-        for _ in range(k):
-            lo = min(l for l, r in T)
-            hi = max(r for l, r in T)
-            delta = hi - lo
-            S = []
-            for start in (2, 6, 10, 14):
-                offset = delta * start - lo
-                for (l, r) in T:
-                    S.append((l + offset, r + offset))
-            S += [
-                (delta * 1,  delta * 5),
-                (delta * 12, delta * 16),
-                (delta * 4,  delta * 9),
-                (delta * 8,  delta * 13),
-            ]
-            T = S
-        return normalize_intervals(T)
-
-    # Return the best found normalized intervals
-    return best[4]
+        for depth in depths:
+            # cap instance size
+            if (4**depth)*(len(base)+len(SHORT_WAVE))>3000: continue
+            for blockers in blockers_set:
+                for translation in translations:
+                    for anchor in anchors:
+                        for wave_type in wave_types:
+                            for eps in epsilons:
+                                T=build_pattern(base,depth,blockers,translation,anchor,wave_type,eps)
+                                sc,om,cols,n,_=evaluate_cached(T)
+                                T1=prune_stage1(T,cols,om)
+                                T2=prune_stage2(T1,cols,om)
+                                cand=evaluate_cached(T2)
+                                if best is None or \
+                                   cand[0]>best[0]+1e-9 or \
+                                   (abs(cand[0]-best[0])<1e-9 and (cand[3]<best[3] or (cand[3]==best[3] and cand[2]>best[2]))):
+                                    best=cand
+    if best:
+        return best[4]
+    # fallback classic
+    T=[(0.0,1.0)]
+    for _ in range(4):
+        lo=min(l for l,r in T); hi=max(r for l,r in T); d=hi-lo
+        S=[(l+d*s-lo,r+d*s-lo) for s in (2,6,10,14) for l,r in T]
+        S+=[(d*1,d*5),(d*12,d*16),(d*4,d*9),(d*8,d*13)]
+        T=S
+    return normalize(T)
 
 # EVOLVE-BLOCK-END
 
 def run_experiment(**kwargs):
   """Main called by evaluator"""
   return construct_intervals()