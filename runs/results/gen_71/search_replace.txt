<NAME>
zigzag_blockers_prune
</NAME>

<DESCRIPTION>
I introduce three synergistic enhancements to push FirstFit higher without inflating omega:

1) Arrival-order engineering inside build_pattern:
   - New schedule option: place blockers before, after, or split between copies in each level.
   - New copy ordering permutations: straight, reverse, and zigzag across offsets.
   - New flip_alt option that reverses the intra-copy arrival order on alternating copies.
   These modifications exploit the sensitivity of FirstFit to the presentation order, while preserving the low-omega recursive gadget.

2) Search-space bug fix:
   - The previous selection logic only kept the last blocker_anchor candidate due to an indentation error. I fix this so every anchor choice is evaluated, improving robustness and potentially the ratio.

3) Deterministic pruning to optimize ratio:
   - A shrink_optimize_by_ratio stage greedily removes intervals that either strictly improve the colors/omega ratio or keep it equal while shrinking n. This post-pass often reduces redundant blockers, sometimes decreasing omega more than colors, improving the ratio or at least the combined score.

Together, these edits implement recommended strategies (arrival-order engineering, layered coupling, and pruning) analogous to techniques from the literature and provide a broader yet controlled search for strong instances. The code remains compatible with the existing API and maintains manageable runtime with size guards.

</DESCRIPTION>

<DIFF>
<<<<<<< SEARCH
def build_pattern(k, base_seed, offsets, blockers, translation, blocker_anchor):
    """
    Recursively expand the base_seed k times using the 4-copy + 4-blocker scheme.
    """
    T = list(base_seed)
    for _ in range(k):
        lo = min(l for l, r in T)
        hi = max(r for l, r in T)
        delta = hi - lo
        center = (lo + hi) / 2.0

        S = []
        S = make_copies(T, offsets, delta, lo, center, translation)
        S = add_blockers(S, blockers, delta, blocker_anchor, center)

        T = S
    return T
=======
def build_pattern(k, base_seed, offsets, blockers, translation, blocker_anchor, schedule='after', permute='id', flip_alt=False):
    """
    Recursively expand the base_seed k times using a multi-copy + blocker scheme with
    engineered arrival orders.

    Args:
      k: recursion depth
      base_seed: initial list of intervals
      offsets: tuple of copy offsets (multipliers of delta)
      blockers: list of 4 pairs (a,b) as multipliers of delta
      translation: 'left' or 'center' anchor for copies
      blocker_anchor: 'left' or 'center' anchor for blockers
      schedule: 'after' | 'before' | 'split' for placing blockers relative to copies
      permute: 'id' | 'rev' | 'zig' reorders the offsets within each level
      flip_alt: if True, alternate reversing the intra-copy arrival order
    """
    def order_offsets(off, mode):
        if mode == 'rev':
            return tuple(reversed(off))
        if mode == 'zig':
            res = []
            i, j = 0, len(off) - 1
            while i <= j:
                res.append(off[i]); i += 1
                if i <= j:
                    res.append(off[j]); j -= 1
            return tuple(res)
        return tuple(off)

    T = list(base_seed)
    for _ in range(k):
        lo = min(l for l, r in T)
        hi = max(r for l, r in T)
        delta = hi - lo
        center = (lo + hi) / 2.0

        # scale blockers
        if blocker_anchor == 'left':
            blk = [(delta * a, delta * b) for (a, b) in blockers]
        else:
            blk = [(delta * a - center, delta * b - center) for (a, b) in blockers]

        # generate copies with engineered order
        offs = order_offsets(offsets, permute)
        copies = []
        for idx, start in enumerate(offs):
            if translation == 'left':
                offset = delta * start - lo
            else:
                offset = delta * start - center
            src = T if not (flip_alt and (idx % 2 == 1)) else list(reversed(T))
            for (l, r) in src:
                copies.append((l + offset, r + offset))

        # Merge according to schedule
        if schedule == 'before':
            S = list(blk) + copies
        elif schedule == 'split':
            mid = len(copies) // 2
            S = copies[:mid] + list(blk) + copies[mid:]
        else:  # 'after'
            S = copies + list(blk)

        T = S
    return T
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
def evaluate(intervals):
    """
    Compute FF colors and omega, with a small penalty for ridiculously large outputs.
    Return (score, omega, num_colors, n, intervals_normalized)
    """
    Tn = normalize_intervals(intervals)
    n = len(Tn)
    if n == 0:
        return (-1.0, 0, 0, n, Tn)
    om = clique_number(Tn)
    if om == 0:
        return (-1.0, 0, 0, n, Tn)
    cols = firstfit_colors(Tn)
    ratio = cols / om
    # soft penalty to prefer smaller n when ratios tie
    score = ratio - 1e-6 * (n / 10000.0)
    return (score, om, cols, n, Tn)

def construct_intervals():
=======
def evaluate(intervals):
    """
    Compute FF colors and omega, with a small penalty for ridiculously large outputs.
    Return (score, omega, num_colors, n, intervals_normalized)
    """
    Tn = normalize_intervals(intervals)
    n = len(Tn)
    if n == 0:
        return (-1.0, 0, 0, n, Tn)
    om = clique_number(Tn)
    if om == 0:
        return (-1.0, 0, 0, n, Tn)
    cols = firstfit_colors(Tn)
    ratio = cols / om
    # soft penalty to prefer smaller n when ratios tie
    score = ratio - 1e-6 * (n / 10000.0)
    return (score, om, cols, n, Tn)

def shrink_optimize_by_ratio(intervals, max_rounds=2):
    """
    Greedy pruning to improve (or preserve) FirstFit/omega ratio.
    Iteratively attempt removing intervals (long-first). Accept a removal if:
      - the ratio strictly increases; or
      - the ratio is unchanged and n decreases (improves the combined score slightly).
    """
    cur = list(intervals)

    def metrics(ints):
        om = clique_number(ints)
        if om <= 0:
            return (0, 0, 0.0)
        cols = firstfit_colors(ints)
        return (cols, om, cols / om)

    cols, om, ratio = metrics(cur)
    if om == 0:
        return cur

    rounds = 0
    improved = True
    while improved and rounds < max_rounds:
        improved = False
        rounds += 1
        # try longer intervals first (tend to be blockers)
        order = sorted(range(len(cur)), key=lambda i: (cur[i][1] - cur[i][0], i), reverse=True)
        for idx in order:
            cand = cur[:idx] + cur[idx + 1:]
            c_cols, c_om, c_ratio = metrics(cand)
            if c_om == 0:
                continue
            if c_ratio > ratio + 1e-12 or (abs(c_ratio - ratio) <= 1e-12 and len(cand) < len(cur)):
                cur = cand
                cols, om, ratio = c_cols, c_om, c_ratio
                improved = True
                break
    return cur

def construct_intervals():
>>>>>>> REPLACE
</DIFF>

<DIFF>
<<<<<<< SEARCH
def construct_intervals():
    """
    Build a sequence of open intervals that aims to maximize FirstFit/OPT.
    We sweep several recommended blueprints and pick the best validated candidate.
    """
    # search space inspired by the provided recommendations
    offsets_set = [
        (2, 6, 10, 14),  # baseline
        (1, 5, 9, 13),
        (3, 7, 11, 15),
        (0, 4, 8, 12),
    ]
    blockers_templates = [
        # Template A: baseline
        ((1, 5), (12, 16), (4, 9), (8, 13)),
        # Template B
        ((0, 4), (6, 10), (8, 12), (14, 18)),
        # Template C
        ((2, 6), (4, 8), (10, 14), (12, 16)),
    ]
    translations = ['left', 'center']  # how copies are positioned
    blocker_anchors = ['left', 'center']  # how blockers are positioned
    depths = [3, 4, 5]  # sweep as recommended
    base_seeds = [
        [(0.0, 1.0)],                      # single seed (classic)
        [(0.0, 1.0), (2.0, 3.0)],          # richer base: two disjoint seeds
    ]
    extra_copies_opts = [0, 1, 2]  # allow up to two extra copies on first level

    best = None  # (score, om, cols, n, intervals)
    # Enumerate combinations with a guard on worst-case explosion
    for base in base_seeds:
        for k in depths:
            # Hard cap: avoid extremely large instances in the inner evaluator
            # expected size ~ 4^k * |base| + O(4^k)
            if (4 ** k) * (len(base) + 4) > 2000:
                continue
            for offsets in offsets_set:
                for extra in extra_copies_opts:
                    # build potentially extended offsets list
                    offs = list(offsets)
                    if extra >= 1:
                        offs.append(offsets[-1] + 4)
                    if extra >= 2:
                        offs.append(offsets[-1] + 8)
                    offs = tuple(offs)
                    for blockers in blockers_templates:
                        for translation in translations:
                            for anchor in blocker_anchors:
                                T = build_pattern(
                                    k=k,
                                    base_seed=base,
                                    offsets=offs,
                                    blockers=blockers,
                                    translation=translation,
                                    blocker_anchor=anchor,
                                )
                                score, om, cols, n, Tn = evaluate(T)

                            cand = (score, om, cols, n, Tn)
                            if best is None:
                                best = cand
                            else:
                                # pick better score; tie-break by fewer intervals then larger cols
                                if cand[0] > best[0] + 1e-9:
                                    best = cand
                                elif abs(cand[0] - best[0]) <= 1e-9:
                                    if cand[3] < best[3]:
                                        best = cand
                                    elif cand[3] == best[3] and cand[2] > best[2]:
                                        best = cand

    # Fallback to baseline if search didn't produce anything
    if best is None:
        # original baseline as a safe default
        k = 4
        T = [(0.0, 1.0)]
        for _ in range(k):
            lo = min(l for l, r in T)
            hi = max(r for l, r in T)
            delta = hi - lo
            S = []
            for start in (2, 6, 10, 14):
                offset = delta * start - lo
                for (l, r) in T:
                    S.append((l + offset, r + offset))
            S += [
                (delta * 1,  delta * 5),
                (delta * 12, delta * 16),
                (delta * 4,  delta * 9),
                (delta * 8,  delta * 13),
            ]
            T = S
        return normalize_intervals(T)

    # Return the best found normalized intervals
    return best[4]
=======
def construct_intervals():
    """
    Build a sequence of open intervals that aims to maximize FirstFit/OPT.
    We sweep several recommended blueprints and pick the best validated candidate.
    Added knobs:
      - schedule of blocker placement within each level
      - permutation of copy offsets (straight/reverse/zigzag)
      - alternating reversal of intra-copy arrival order
      - conservative pruning to improve ratio or reduce size without hurting ratio
    """
    # search space inspired by the provided recommendations
    offsets_set = [
        (2, 6, 10, 14),  # baseline
        (1, 5, 9, 13),
        (3, 7, 11, 15),
        (0, 4, 8, 12),
    ]
    blockers_templates = [
        # Template A: baseline
        ((1, 5), (12, 16), (4, 9), (8, 13)),
        # Template B
        ((0, 4), (6, 10), (8, 12), (14, 18)),
        # Template C
        ((2, 6), (4, 8), (10, 14), (12, 16)),
    ]
    translations = ['left', 'center']  # how copies are positioned
    blocker_anchors = ['left', 'center']  # how blockers are positioned
    depths = [3, 4, 5]  # sweep as recommended
    base_seeds = [
        [(0.0, 1.0)],                      # single seed (classic)
        [(0.0, 1.0), (2.0, 3.0)],          # richer base: two disjoint seeds
    ]
    extra_copies_opts = [0, 1, 2]  # allow up to two extra copies on first level

    schedules = ['after', 'before', 'split']
    permutations = ['id', 'rev', 'zig']
    flip_opts = [False, True]

    best = None  # (score, om, cols, n, intervals_normalized)

    # Enumerate combinations with a guard on worst-case explosion
    for base in base_seeds:
        for k in depths:
            for offsets in offsets_set:
                for extra in extra_copies_opts:
                    # build potentially extended offsets list
                    offs = list(offsets)
                    if extra >= 1:
                        offs.append(offs[-1] + 4)
                    if extra >= 2:
                        offs.append(offs[-1] + 8)
                    offs = tuple(offs)

                    # rough size guard based on branching p=len(offs)
                    p = len(offs)
                    base_sz = len(base)
                    approx = (p ** k) * base_sz + 4 * sum(p ** i for i in range(1, k + 1))
                    if approx > 3000:
                        continue

                    for blockers in blockers_templates:
                        for translation in translations:
                            for anchor in blocker_anchors:
                                for sch in schedules:
                                    for perm in permutations:
                                        for flip in flip_opts:
                                            T = build_pattern(
                                                k=k,
                                                base_seed=base,
                                                offsets=offs,
                                                blockers=blockers,
                                                translation=translation,
                                                blocker_anchor=anchor,
                                                schedule=sch,
                                                permute=perm,
                                                flip_alt=flip,
                                            )
                                            score, om, cols, n, Tn = evaluate(T)
                                            cand = (score, om, cols, n, Tn)
                                            if best is None:
                                                best = cand
                                            else:
                                                # pick better score; tie-break by fewer intervals then larger cols
                                                if cand[0] > best[0] + 1e-9:
                                                    best = cand
                                                elif abs(cand[0] - best[0]) <= 1e-9:
                                                    if cand[3] < best[3]:
                                                        best = cand
                                                    elif cand[3] == best[3] and cand[2] > best[2]:
                                                        best = cand

    # Fallback to baseline if search didn't produce anything
    if best is None:
        # original baseline as a safe default
        k = 4
        T = [(0.0, 1.0)]
        for _ in range(k):
            lo = min(l for l, r in T)
            hi = max(r for l, r in T)
            delta = hi - lo
            S = []
            for start in (2, 6, 10, 14):
                offset = delta * start - lo
                for (l, r) in T:
                    S.append((l + offset, r + offset))
            S += [
                (delta * 1,  delta * 5),
                (delta * 12, delta * 16),
                (delta * 4,  delta * 9),
                (delta * 8,  delta * 13),
            ]
            T = S
        return normalize_intervals(T)

    # Apply a conservative pruning pass to potentially improve ratio or reduce n
    pruned = shrink_optimize_by_ratio(best[4], max_rounds=2)
    return pruned if pruned else best[4]
>>>>>>> REPLACE
</DIFF>