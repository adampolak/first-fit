--- a/original.py
+++ b/original.py
@@ -1,319 +1,457 @@
 # EVOLVE-BLOCK-START
 
 from math import gcd
-from functools import reduce
-
-def overlaps(a, b):
-    """Open-interval overlap test: return True iff intervals overlap."""
-    (l1, r1), (l2, r2) = a, b
-    return max(l1, l2) < min(r1, r2)
-
-def firstfit_colors(intervals):
-    """
-    Simulate FirstFit coloring on the given arrival order.
-    Return total number of colors used.
-    """
-    colors = []  # list of color classes; each is a list of intervals in arrival order
-    for iv in intervals:
+
+# -------------------- Core utilities --------------------
+
+def _normalize_to_grid(intervals):
+    """
+    Normalize endpoints to a compact integer grid while preserving order.
+    Map unique endpoints to even integers in increasing order.
+    """
+    if not intervals:
+        return []
+    endpoints = sorted(set([x for seg in intervals for x in seg]))
+    coord = {}
+    cur = 0
+    for e in endpoints:
+        coord[e] = cur
+        cur += 2
+    return [(coord[l], coord[r]) for (l, r) in intervals]
+
+def _ff_with_witness(intervals):
+    """
+    Simulate FirstFit on open intervals with arrival order as given.
+    Returns:
+      - num_colors
+      - color assignment list
+      - witness set of indices necessary to sustain observed color frontier
+    For FirstFit on intervals, color availability depends only on last_end per color.
+    We record a witness each time a new color is created: the new interval index and
+    the last intervals (by index) of colors that were blocked (l < last_end[color]).
+    """
+    last_end = []     # last end per color
+    last_idx = []     # last interval index placed in each color
+    colors = []       # color assignment per interval
+    witness = set()   # indices of intervals that serve as witnesses for the frontier
+    for i, (l, r) in enumerate(intervals):
         placed = False
-        for c in colors:
-            conflict = False
-            # Check conflict within this color class (pairwise disjoint invariant holds,
-            # but we conservatively check all to stay robust)
-            for u in c:
-                if overlaps(u, iv):
-                    conflict = True
-                    break
-            if not conflict:
-                c.append(iv)
+        for c in range(len(last_end)):
+            if l >= last_end[c]:
+                # can place in color c
+                last_end[c] = r
+                last_idx[c] = i
+                colors.append(c)
                 placed = True
                 break
         if not placed:
-            colors.append([iv])
-    return len(colors)
-
-def clique_number(intervals):
-    """
-    Compute omega (maximum number of intervals covering a single point) using sweep.
-    For open intervals, endpoints do not contribute to overlap.
-    """
-    events = []  # (x, type) where type=-1 for right endpoint, +1 for left endpoint
+            # new color used; block all smaller colors that were active at l
+            # those are exactly the colors with last_end[c] > l
+            for c in range(len(last_end)):
+                if l < last_end[c]:
+                    witness.add(last_idx[c])
+            witness.add(i)
+            last_end.append(r)
+            last_idx.append(i)
+            colors.append(len(last_end) - 1)
+    return len(last_end), colors, witness
+
+def _ff_count(intervals):
+    """FirstFit color count only."""
+    last_end = []
     for (l, r) in intervals:
-        if l >= r:
-            continue
-        events.append((l, +1))
-        events.append((r, -1))
-    # For open intervals, at the same coordinate handle -1 before +1
+        for i, e in enumerate(last_end):
+            if l >= e:
+                last_end[i] = r
+                break
+        else:
+            last_end.append(r)
+    return len(last_end)
+
+def _omega_open(intervals):
+    """
+    Compute omega (max number of intervals covering a point) via sweep for open intervals.
+    Ties resolved with right endpoints before left endpoints.
+    """
+    events = []
+    for (l, r) in intervals:
+        if l < r:
+            events.append((l, +1))
+            events.append((r, -1))
     events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
-    cur = 0
-    best = 0
+    cur = best = 0
     for _, t in events:
         cur += t
         if cur > best:
             best = cur
     return best
 
-def make_copies(T, offsets, delta, lo, center, translation):
-    """
-    Create 4 translated copies of T according to offsets and translation rule.
-    translation in {'left', 'center'}.
-    """
-    S = []
-    for start in offsets:
-        if translation == 'left':
-            offset = delta * start - lo
-        else:  # center-based
-            offset = delta * start - center
-        for (l, r) in T:
-            S.append((l + offset, r + offset))
-    return S
-
-def add_blockers(S, blockers, delta, anchor, center):
-    """
-    Add 4 blockers scaled by delta. Anchor may be 'left' (absolute) or 'center' (center-shifted).
-    """
-    for (a, b) in blockers:
-        if anchor == 'left':
-            S.append((delta * a, delta * b))
-        else:
-            S.append((delta * a - center, delta * b - center))
-    return S
-
-def build_pattern(k, base_seed, offsets, blockers, translation, blocker_anchor):
-    """
-    Recursively expand the base_seed k times using the 4-copy + 4-blocker scheme.
-    """
-    T = list(base_seed)
-    for _ in range(k):
-        lo = min(l for l, r in T)
-        hi = max(r for l, r in T)
-        delta = hi - lo
-        center = (lo + hi) / 2.0
-
-        S = []
-        S = make_copies(T, offsets, delta, lo, center, translation)
-        S = add_blockers(S, blockers, delta, blocker_anchor, center)
-
-        T = S
-    return T
-
-def normalize_intervals(intervals):
-    """
-    Normalize to small integer coordinates:
-    - scale by 2 to eliminate .5 if produced by center shifts
-    - translate so min coordinate is >= 0
-    - (optional) divide by global gcd to shrink
+def _normalize_small_integers(intervals):
+    """
+    Deterministic integer normalization that preserves relative geometry reasonably:
+    - scale by 2 to remove .5 if produced by center anchors
+    - translate so min >= 0
+    - divide by gcd of all coordinates when possible
     """
     if not intervals:
-        return intervals
-    # scale by 2 and round (the construction only yields multiples of 0.5)
+        return []
     scaled = []
     for (l, r) in intervals:
         L = int(round(l * 2))
         R = int(round(r * 2))
         scaled.append((L, R))
     min_coord = min(min(l, r) for l, r in scaled)
     shifted = [(l - min_coord, r - min_coord) for (l, r) in scaled]
-    # Keep integers modestâ€”divide by gcd of all endpoints if possible
     vals = []
     for (l, r) in shifted:
         vals.append(abs(l))
         vals.append(abs(r))
     g = 0
     for v in vals:
         g = gcd(g, v)
     if g > 1:
         shrunk = [(l // g, r // g) for (l, r) in shifted]
     else:
         shrunk = shifted
     return shrunk
 
-def evaluate(intervals):
-    """
-    Compute FF colors and omega, with a small penalty for ridiculously large outputs.
-    Return (score, omega, num_colors, n, intervals_normalized)
-    """
-    Tn = normalize_intervals(intervals)
-    n = len(Tn)
-    if n == 0:
-        return (-1.0, 0, 0, n, Tn)
-    om = clique_number(Tn)
+# -------------------- Pattern engine --------------------
+
+def _make_copies(base, offsets, delta, anchor_lo, anchor_center, translation):
+    S = []
+    for start in offsets:
+        if translation == 'left':
+            off = delta * start - anchor_lo
+        else:
+            off = delta * start - anchor_center
+        for (l, r) in base:
+            S.append((l + off, r + off))
+    return S
+
+def _add_blockers(S, blockers, delta, anchor, center):
+    for (a, b) in blockers:
+        if anchor == 'left':
+            S.append((delta * a, delta * b))
+        else:
+            S.append((delta * a - center, delta * b - center))
+    return S
+
+def _build_level(base, offsets, blockers, schedule, translation, blocker_anchor):
+    lo = min(l for l, r in base)
+    hi = max(r for l, r in base)
+    delta = hi - lo
+    center = (lo + hi) / 2.0
+    # copies and blockers by schedule
+    copies = _make_copies(base, offsets, delta, lo, center, translation)
+    blks = []
+    for (a, b) in blockers:
+        if blocker_anchor == 'left':
+            blks.append((delta * a, delta * b))
+        else:
+            blks.append((delta * a - center, delta * b - center))
+    if schedule == 'after':
+        return copies + blks
+    elif schedule == 'before':
+        return blks + copies
+    elif schedule == 'split':
+        h = len(offsets) // 2
+        return _make_copies(base, offsets[:h], delta, lo, center, translation) + blks + _make_copies(base, offsets[h:], delta, lo, center, translation)
+    else:  # interleave: copy i then blocker i (if any)
+        S = []
+        for idx, start in enumerate(offsets):
+            off = delta * start - (lo if translation == 'left' else center)
+            for (l, r) in base:
+                S.append((l + off, r + off))
+            if idx < len(blks):
+                S.append(blks[idx])
+        return S
+
+def _evaluate(intervals):
+    Tn = _normalize_small_integers(intervals)
+    if not Tn:
+        return -1.0, 0, 0, 0, Tn
+    om = _omega_open(Tn)
     if om == 0:
-        return (-1.0, 0, 0, n, Tn)
-    cols = firstfit_colors(Tn)
+        return -1.0, 0, 0, len(Tn), Tn
+    cols = _ff_count(Tn)
     ratio = cols / om
-    # soft penalty to prefer smaller n when ratios tie
-    score = ratio - 1e-6 * (n / 10000.0)
-    return (score, om, cols, n, Tn)
-
-def shrink_prune(intervals, target_ratio):
-    """
-    Conservative pruning: try removing intervals one-by-one (prefer longer ones first).
-    Accept removal only if observed FirstFit/OPT ratio remains >= target_ratio.
-    Deterministic and cheap; helps reduce redundant long blockers while preserving power.
-    """
-    cur = list(intervals)
-    # compute current ratio
-    cur_norm = normalize_intervals(cur)
-    cur_alg = firstfit_colors(cur_norm)
-    cur_opt = clique_number(cur_norm)
-    if cur_opt == 0:
-        return cur
-    base_ratio = cur_alg / cur_opt
-    # target is the maximum allowed drop (we only accept removals that keep ratio >= target_ratio)
-    if target_ratio is None:
-        target_ratio = base_ratio
-
-    # attempt removals in order of decreasing interval length (prefer removing long blockers)
-    def length(iv):
-        return iv[1] - iv[0]
-    order = sorted(range(len(cur)), key=lambda i: (-length(cur[i]), i))
-    changed = True
-    while changed:
-        changed = False
-        for idx in list(order):
-            if idx >= len(cur):
-                continue
-            cand = cur[:idx] + cur[idx + 1 :]
-            cand_norm = normalize_intervals(cand)
-            alg = firstfit_colors(cand_norm)
-            opt = clique_number(cand_norm)
-            if opt == 0:
-                continue
-            ratio = alg / opt
-            # accept only if ratio not dropping below target_ratio
-            if ratio >= target_ratio:
-                cur = cand
-                # recompute order (lengths changed)
-                order = sorted(range(len(cur)), key=lambda i: (-length(cur[i]), i))
-                changed = True
-                break
-    return cur
-
-def construct_intervals():
-    """
-    Build a sequence of open intervals that aims to maximize FirstFit/OPT.
-    We sweep several recommended blueprints and pick the best validated candidate.
-
-    Improvements:
-      - small extra_copies option (0/1) to append a single extra translated copy
-        on the first level to diversify geometry slightly.
-      - conservative shrink_prune postprocessing to remove redundant intervals.
-    """
-    # search space inspired by the provided recommendations
-    offsets_set = [
-        (2, 6, 10, 14),  # baseline
-        (1, 5, 9, 13),
-        (3, 7, 11, 15),
-        (0, 4, 8, 12),
+    # penalize size slightly on tie
+    score = ratio - 1e-6 * (len(Tn) / 10000.0)
+    return score, om, cols, len(Tn), Tn
+
+def _beam_build_skeleton(depth_max=4, beam_width=6):
+    """
+    Deterministic beam search over level-by-level construction.
+    At each level, rotate among A/B/C/D tilings and several blocker templates and schedules.
+    Keep a small beam of best partial constructions by observed FF/omega.
+    """
+    # copy-offset patterns (A/B/C/D)
+    tilings_cycle = [
+        (2, 6, 10, 14),  # A
+        (1, 5, 9, 13),   # B
+        (3, 7, 11, 15),  # C
+        (0, 4, 8, 12),   # D
     ]
-    blockers_templates = [
-        # Template A: baseline
-        ((1, 5), (12, 16), (4, 9), (8, 13)),
-        # Template B
-        ((0, 4), (6, 10), (8, 12), (14, 18)),
-        # Template C
-        ((2, 6), (4, 8), (10, 14), (12, 16)),
-        # Template D: lengthened first and second
-        ((1, 6), (11, 16), (4, 9), (8, 13)),
-        # Template E: shifted and broadened
-        ((0, 5), (10, 15), (3, 8), (7, 12)),
+    blocker_templates = [
+        ((1, 5), (12, 16), (4, 9), (8, 13)),              # canonical
+        ((1, 6), (11, 16), (3, 9), (7, 13)),              # lengthened
+        ((0, 4), (6, 10), (8, 12), (14, 18)),             # shifted
     ]
-    translations = ['left', 'center']  # how copies are positioned
-    blocker_anchors = ['left', 'center']  # how blockers are positioned
-    depths = [3, 4, 5]  # sweep as recommended
-    base_seeds = [
-        [(0.0, 1.0)],                      # single seed (classic)
-        [(0.0, 1.0), (2.0, 3.0)],          # richer base: two disjoint seeds
-    ]
-    extra_copies_opts = [0, 1, 2]  # allow a single extra translated copy on first level, or prepended copy
-
-    best = None  # (score, om, cols, n, intervals, raw_intervals)
-    # Enumerate combinations with a guard on worst-case explosion
-    for base in base_seeds:
-        for k in depths:
-            # Hard cap: avoid extremely large instances in the inner evaluator
-            # expected size ~ 4^k * |base| + O(4^k)
-            if (4 ** k) * (len(base) + 2) > 2000:
-                continue
-            for offsets in offsets_set:
-                for blockers in blockers_templates:
-                    for translation in translations:
-                        for anchor in blocker_anchors:
-                            for extra in extra_copies_opts:
-                                # build offsets possibly extended by extra copies (small geometry variation)
-                                offs = tuple(offsets)
-                                if extra == 1:
-                                    # append an extra copy to the right
-                                    last = offs[-1] if len(offs) > 0 else 0
-                                    offs = tuple(list(offs) + [last + 4])
-                                elif extra == 2:
-                                    # prepend an extra copy to the left
-                                    first = offs[0] if len(offs) > 0 else 0
-                                    offs = tuple([first - 4] + list(offs))
-                                # Build raw pattern using these offsets
-                                T = build_pattern(
-                                    k=k,
-                                    base_seed=base,
-                                    offsets=offs,
-                                    blockers=blockers,
-                                    translation=translation,
-                                    blocker_anchor=anchor,
-                                )
-                                score, om, cols, n, Tn = evaluate(T)
-
-                                cand = (score, om, cols, n, Tn, T)
-                                if best is None:
-                                    best = cand
-                                else:
-                                    # pick better score; tie-break by fewer intervals then larger cols
-                                    if cand[0] > best[0] + 1e-9:
-                                        best = cand
-                                    elif abs(cand[0] - best[0]) <= 1e-9:
-                                        if cand[3] < best[3]:
-                                            best = cand
-                                        elif cand[3] == best[3] and cand[2] > best[2]:
-                                            best = cand
-
-    # Fallback to baseline if search didn't produce anything
-    if best is None:
-        # original baseline as a safe default
-        k = 4
+    schedules = ['after', 'before', 'split', 'interleave']
+    translations = ['left', 'center']
+    anchors = ['left', 'center']
+
+    # initial seed
+    beam = [([(0.0, 1.0)], _evaluate([(0.0, 1.0)]))]  # (intervals, eval)
+    for lvl in range(depth_max):
+        new_beam = []
+        for base, _ in beam:
+            # choose tiling based on level index to enforce diversity
+            starts = tilings_cycle[lvl % len(tilings_cycle)]
+            for blks in blocker_templates:
+                for sch in schedules:
+                    for tr in translations:
+                        for anc in anchors:
+                            cand = _build_level(base, starts, blks, sch, tr, anc)
+                            sc, om, cols, n, Tn = _evaluate(cand)
+                            # Keep candidates bounded: avoid explosion
+                            if n == 0:
+                                continue
+                            new_beam.append((cand, (sc, om, cols, n, Tn)))
+        # select best beam_width by score then fewer intervals then more colors
+        new_beam.sort(key=lambda x: (-(x[1][0]), x[1][3], -x[1][2]))
+        beam = new_beam[:beam_width]
+        if not beam:
+            break
+
+    # best final
+    beam.sort(key=lambda x: (-(x[1][0]), x[1][3], -x[1][2]))
+    if not beam:
+        # safe fallback: 4-copy 4-blocker depth=4
         T = [(0.0, 1.0)]
-        for _ in range(k):
+        for _ in range(4):
             lo = min(l for l, r in T)
             hi = max(r for l, r in T)
             delta = hi - lo
             S = []
             for start in (2, 6, 10, 14):
-                offset = delta * start - lo
+                off = delta * start - lo
                 for (l, r) in T:
-                    S.append((l + offset, r + offset))
+                    S.append((l + off, r + off))
             S += [
                 (delta * 1,  delta * 5),
                 (delta * 12, delta * 16),
                 (delta * 4,  delta * 9),
                 (delta * 8,  delta * 13),
             ]
             T = S
-        return normalize_intervals(T)
-
-    # Apply conservative pruning to the raw best intervals to remove redundant blockers
-    raw_best = best[5]
-    # preserve the measured best ratio (no drop allowed)
-    best_score, best_om, best_cols, _, _, _ = best
-    # target ratio is best_cols / best_om (exact observed)
-    target_ratio = best_cols / best_om if best_om > 0 else None
-    pruned_raw = shrink_prune(raw_best, target_ratio)
-
-    final = normalize_intervals(pruned_raw)
-    # sanity check: if pruning accidentally removed everything, fall back to best normalized
+        return _normalize_small_integers(T)
+    # normalize the best skeleton to integer grid
+    return _normalize_small_integers(beam[0][0])
+
+# -------------------- Wave augmentation --------------------
+
+def _coverage_segments(intervals):
+    """
+    Compute coverage counts on atomic segments between unique endpoints.
+    Returns (coords, segment_coverages) where segment i is (coords[i], coords[i+1]).
+    """
+    if not intervals:
+        return [], []
+    coords = sorted(set([x for iv in intervals for x in iv]))
+    events = []
+    for (l, r) in intervals:
+        if l < r:
+            events.append((l, +1))
+            events.append((r, -1))
+    events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
+    cur = 0
+    seg_cov = []
+    ev_idx = 0
+    for i in range(len(coords) - 1):
+        x = coords[i]
+        # process all events at x
+        while ev_idx < len(events) and events[ev_idx][0] == x:
+            cur += events[ev_idx][1]
+            ev_idx += 1
+        seg_cov.append(cur)
+    return coords, seg_cov
+
+def _try_append_interval(current, cand, omega_limit):
+    """
+    Try appending cand to 'current' and check omega constraint.
+    Returns (ok, new_seq, new_cols, new_omega, new_ratio)
+    """
+    new_seq = current + [cand]
+    new_omega = _omega_open(new_seq)
+    if new_omega > omega_limit:
+        return (False, current, None, None, None)
+    new_cols = _ff_count(new_seq)
+    if new_omega == 0:
+        return (False, current, None, None, None)
+    return (True, new_seq, new_cols, new_omega, new_cols / new_omega)
+
+def _augment_with_waves(base_seq, max_steps=80):
+    """
+    Deterministic greedy hill-climber:
+    - Compute coverage map.
+    - Generate candidate short and medium intervals inside low-coverage corridors.
+    - Accept a candidate only if FF/omega strictly improves.
+    Allow at most +1 omega if the color gain >= 3 (guarded).
+    """
+    cur = list(base_seq)
+    base_cols = _ff_count(cur)
+    base_om = _omega_open(cur) or 1
+    best_ratio = base_cols / base_om
+
+    coords, seg_cov = _coverage_segments(cur)
+    if len(coords) < 3:
+        return cur  # nothing to augment
+
+    # candidate lengths (short/long waves)
+    lengths = sorted(set([
+        max(1, (coords[-1] - coords[0]) // 60),
+        max(2, (coords[-1] - coords[0]) // 45),
+        2, 3, 4, 5, 6, 7
+    ]))
+    # sample candidate lefts from low-coverage segments; also a coarse global grid
+    low_cov_targets = [c for c in range(min(seg_cov, default=0), base_om + 1)]
+    # coarse global steps
+    span = max(1, coords[-1] - coords[0])
+    coarse_step = max(1, span // 40)
+
+    steps = 0
+    improved = True
+    while steps < max_steps and improved:
+        steps += 1
+        improved = False
+        # recompute coverage each iteration to reflect accepted changes
+        coords, seg_cov = _coverage_segments(cur)
+        # collect candidate left endpoints
+        lefts = set()
+        for i, cov in enumerate(seg_cov):
+            if cov in low_cov_targets:
+                L = coords[i]
+                R = coords[i+1]
+                lefts.add(L)
+                lefts.add(max(L, (L + R) // 2))
+                if R - L >= 3:
+                    lefts.add(R - 2)
+        # coarse global grid points
+        for x in range(coords[0], coords[-1], coarse_step):
+            lefts.add(x)
+        # restrict to deterministic order
+        lefts = sorted(lefts)
+        # allowable omega limit: usually base_om; allow +1 if sufficiently large gain
+        for wl in lengths:
+            for l in lefts:
+                r = l + wl
+                if r <= l + 0:
+                    continue
+                # hard guard: do not exceed far rightmost endpoint by too much
+                if r > coords[-1] + wl * 2:
+                    continue
+                # primary attempt: keep omega unchanged
+                ok, new_seq, new_cols, new_om, new_ratio = _try_append_interval(cur, (l, r), base_om)
+                if ok and new_ratio > best_ratio + 1e-12:
+                    cur = new_seq
+                    best_ratio = new_ratio
+                    improved = True
+                    break
+                # secondary attempt: allow +1 omega only if at least +3 colors
+                ok2, new_seq2, new_cols2, new_om2, new_ratio2 = _try_append_interval(cur, (l, r), base_om + 1)
+                if ok2 and new_om2 <= base_om + 1 and (new_cols2 - base_cols) >= 3 and new_ratio2 > best_ratio + 1e-12:
+                    cur = new_seq2
+                    base_om = new_om2
+                    best_ratio = new_ratio2
+                    improved = True
+                    break
+            if improved:
+                # update base_cols after acceptance
+                base_cols = _ff_count(cur)
+                break
+    return cur
+
+# -------------------- Witness-preserving pruning --------------------
+
+def _prune_preserve_witness(intervals, keep_ratio):
+    """
+    Two-stage deterministic pruning that preserves color-frontier witnesses.
+    Stage 1: remove longest non-witness intervals if ratio stays >= keep_ratio.
+    Stage 2: lighter pass over remaining non-witness with stable ordering.
+    """
+    if not intervals:
+        return intervals
+    # compute witness set on current instance
+    cols, _, witness = _ff_with_witness(intervals)
+    om = _omega_open(intervals) or 1
+    base_ratio = cols / om
+    target = keep_ratio if keep_ratio is not None else base_ratio
+
+    def length(iv):
+        return iv[1] - iv[0]
+
+    cur = list(intervals)
+    # Stage 1: remove long non-witness greedily
+    order = sorted([i for i in range(len(cur)) if i not in witness], key=lambda i: (-length(cur[i]), i))
+    changed = True
+    while changed and order:
+        changed = False
+        for idx in list(order):
+            if idx >= len(cur):
+                continue
+            cand = cur[:idx] + cur[idx+1:]
+            new_cols = _ff_count(cand)
+            new_om = _omega_open(cand) or 1
+            if new_cols / new_om >= target - 1e-12:
+                cur = cand
+                # recompute witness and order after mutation
+                _, _, witness = _ff_with_witness(cur)
+                order = sorted([i for i in range(len(cur)) if i not in witness], key=lambda i: (-length(cur[i]), i))
+                changed = True
+                break
+    # Stage 2: stable pass, try removing remaining non-witness by index order
+    order2 = [i for i in range(len(cur)) if i not in witness]
+    for idx in reversed(order2):
+        cand = cur[:idx] + cur[idx+1:]
+        new_cols = _ff_count(cand)
+        new_om = _omega_open(cand) or 1
+        if new_cols / new_om >= target - 1e-12:
+            cur = cand
+            _, _, witness = _ff_with_witness(cur)
+    return cur
+
+# -------------------- Main constructor --------------------
+
+def construct_intervals():
+    """
+    Build intervals to maximize FirstFit colors divided by omega.
+    Pipeline:
+      1) Beam-built skeleton across diversified templates.
+      2) Wave augmentation under omega guard to raise colors faster than omega.
+      3) Witness-preserving pruning to keep the instance compact without losing ratio.
+    Returns a list of integer open intervals in arrival order.
+    """
+    # 1) Beam skeleton
+    skeleton = _beam_build_skeleton(depth_max=4, beam_width=6)
+    if not skeleton:
+        return []
+    # 2) Wave augmentation
+    augmented = _augment_with_waves(skeleton, max_steps=60)
+    # 3) Prune conservatively without losing observed ratio
+    cols = _ff_count(augmented)
+    om = _omega_open(augmented) or 1
+    ratio = cols / om
+    pruned = _prune_preserve_witness(augmented, ratio)
+    # final normalization to a compact integer grid for stability
+    final = _normalize_to_grid(pruned)
+    # sanity fallback if pruning failed too hard
     if not final:
-        return best[4]
+        return _normalize_to_grid(augmented)
     return final
 
 # EVOLVE-BLOCK-END
 
 def run_experiment(**kwargs):
   """Main called by evaluator"""
   return construct_intervals()