--- a/original.py
+++ b/original.py
@@ -1,359 +1,275 @@
 # EVOLVE-BLOCK-START
 
 from math import gcd
-from itertools import islice
-
-# ---------- Basic geometric and algorithmic utilities ----------
+
+# ---------- Core utilities: geometry, FirstFit, clique ----------
 
 def overlaps(a, b):
-    """Open-interval overlap test: True iff intervals overlap."""
     (l1, r1), (l2, r2) = a, b
     return max(l1, l2) < min(r1, r2)
 
 def firstfit_colors(intervals):
     """
-    Simulate FirstFit coloring on the given arrival order of open intervals.
-    Returns number of colors used.
-    """
-    colors = []  # lists of intervals per color (intervals in arrival order)
+    Simulate FirstFit coloring for the given arrival order.
+    Uses per-color conflict checks (robust to arbitrary arrival order).
+    """
+    colors = []
     for iv in intervals:
         placed = False
-        for cls in colors:
-            # since each color class must be pairwise disjoint, we can check last interval only,
-            # but to be safe (and robust under non-sorted classes) check all.
-            conflict = False
-            for u in cls:
-                if overlaps(u, iv):
-                    conflict = True
+        for c in colors:
+            # check conflict against all intervals in color c
+            ok = True
+            for u in c:
+                if overlaps(iv, u):
+                    ok = False
                     break
-            if not conflict:
-                cls.append(iv)
+            if ok:
+                c.append(iv)
                 placed = True
                 break
         if not placed:
             colors.append([iv])
     return len(colors)
 
 def clique_number(intervals):
     """
-    Compute omega = maximum number of open intervals covering some point,
-    by a sweep-line on endpoints. Right endpoints processed before left endpoints
-    at ties to model open intervals correctly.
-    """
-    events = []
+    Compute omega = max number of open intervals covering a single point.
+    Sweep with right endpoints processed before left endpoints at ties.
+    """
+    ev = []
     for (l, r) in intervals:
-        if l >= r:
-            continue
-        events.append((l, +1))
-        events.append((r, -1))
-    # sort so (-1) comes before (+1) at same coordinate
-    events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
+        if l < r:
+            ev.append((l, +1))
+            ev.append((r, -1))
+    ev.sort(key=lambda x: (x[0], 0 if x[1] == -1 else 1))
     cur = best = 0
-    for _, t in events:
+    for _, t in ev:
         cur += t
         if cur > best:
             best = cur
     return best
 
 def normalize_to_grid(intervals):
     """
-    Map all unique endpoints to a compact integer grid with spacing 2 between
-    consecutive unique endpoints (so we can safely place half-length intervals).
-    Returns list of integer intervals (l, r).
+    Map unique endpoints to a compact even-integer grid while preserving order.
     """
     if not intervals:
         return []
-    eps = sorted(set(x for seg in intervals for x in seg))
-    coord = {}
+    pts = sorted({x for seg in intervals for x in seg})
+    mp = {}
     cur = 0
-    for e in eps:
-        coord[e] = cur
+    for x in pts:
+        mp[x] = cur
         cur += 2
-    return [(coord[l], coord[r]) for (l, r) in intervals]
-
-# ---------- Recursive base pattern builder (Figure-4 style) ----------
-
-def build_recursive_pattern(base_seed, depth, offsets=(2,6,10,14), blockers=((1,5),(12,16),(4,9),(8,13)), extra_first=False):
-    """
-    Build the recursive four-copy + four-blocker pattern.
-      - base_seed: list of (l,r) floats
-      - depth: number of recursive levels
-      - offsets: tuple of copy-start multipliers
-      - blockers: list of (a,b) multipliers for long connectors
-      - extra_first: if True, add one extra copy at level 0 (small variant)
-    """
-    T = [tuple(iv) for iv in base_seed]
+    return [(mp[l], mp[r]) for (l, r) in intervals]
+
+def normalize_and_reduce_gcd(intervals):
+    """
+    Normalize to even-integer grid and divide by global gcd to keep footprint small.
+    """
+    if not intervals:
+        return []
+    L = normalize_to_grid(intervals)
+    g = 0
+    for a, b in L:
+        g = gcd(g, abs(a))
+        g = gcd(g, abs(b))
+    if g > 1:
+        L = [(a // g, b // g) for (a, b) in L]
+    return L
+
+# ---------- Blueprint: 4-copy expansion with blockers ----------
+
+def expand_once(seed, offsets, blockers):
+    """
+    One expansion level:
+      - Place |offsets| translated copies of seed by multipliers in 'offsets'.
+      - Add long 'blockers' given as multipliers (a, b) of delta.
+    """
+    if not seed:
+        return []
+    lo = min(l for l, r in seed)
+    hi = max(r for l, r in seed)
+    delta = hi - lo
+    S = []
+    for s in offsets:
+        off = delta * s - lo
+        for (l, r) in seed:
+            S.append((l + off, r + off))
+    for (a, b) in blockers:
+        S.append((delta * a, delta * b))
+    return S
+
+def build_pattern(depth, offsets, blockers, schedule='after', add_extra_first=False, normalize_schedule='final'):
+    """
+    Build a multi-level pattern with:
+      - depth in {3,4,5} explored by search
+      - offsets: tuple of four (or more) start multipliers
+      - blockers: list of four connector multipliers
+      - schedule: 'before'|'after'|'split' (blockers placement within level)
+      - add_extra_first: add a fifth copy at level 0 (offsets + {last+4})
+      - normalize_schedule: 'none'|'each'|'every2'|'final'
+    """
+    T = [(0.0, 1.0)]
     for lvl in range(depth):
-        lo = min(l for l,r in T)
-        hi = max(r for l,r in T)
+        offs = list(offsets)
+        if add_extra_first and lvl == 0:
+            offs = offs + [offs[-1] + 4]
+        # choose schedule
+        lo = min(l for l, r in T)
+        hi = max(r for l, r in T)
         delta = hi - lo
-        S = []
-        offs = list(offsets)
-        if extra_first:
-            # add a further copy step (+4) at every level
-            offs = offs + [offs[-1] + 4]
-        for start in offs:
-            off = delta * start - lo
-            for (l,r) in T:
-                S.append((l + off, r + off))
-        for (a,b) in blockers:
-            S.append((delta * a, delta * b))
+
+        def copies_list(sub_offsets):
+            S = []
+            base_lo = lo
+            for s in sub_offsets:
+                off = delta * s - base_lo
+                for (l, r) in T:
+                    S.append((l + off, r + off))
+            return S
+
+        block_list = [(delta * a, delta * b) for (a, b) in blockers]
+
+        if schedule == 'before':
+            S = list(block_list) + copies_list(offs)
+        elif schedule == 'after':
+            S = copies_list(offs) + list(block_list)
+        else:  # 'split'
+            h = len(offs) // 2
+            S = copies_list(offs[:h]) + list(block_list) + copies_list(offs[h:])
+
         T = S
+
+        # optional mid-level normalization to perturb tie structure deterministically
+        if normalize_schedule == 'each':
+            T = normalize_to_grid(T)
+        elif normalize_schedule == 'every2' and (lvl % 2 == 1):
+            T = normalize_to_grid(T)
+
+    # final normalization policy
+    if normalize_schedule in ('final', 'each', 'every2'):
+        T = normalize_and_reduce_gcd(T)
     return T
 
-# ---------- Greedy augmentation (waves) ----------
-
-def compute_coverage_map(intervals):
-    """
-    Given integer intervals, compute coverage count for each atomic segment between sorted endpoints.
-    Returns:
-      - coords: sorted unique endpoints
-      - seg_counts: list of coverage counts for intervals (coords[i], coords[i+1])
-    """
-    if not intervals:
-        return [], []
-    endpoints = sorted(set(x for iv in intervals for x in iv))
-    events = []
-    for (l,r) in intervals:
-        if l >= r:
-            continue
-        events.append((l, +1))
-        events.append((r, -1))
-    events.sort(key=lambda e: (e[0], 0 if e[1] == -1 else 1))
-    coords = sorted(set(e[0] for e in events))
-    # build segment coverage between consecutive coords
-    seg_counts = []
-    cur = 0
-    # iterate events and produce counts for each interval between distinct coords
-    # create dict from coord->current coverage after processing events at that coord
-    idx = 0
-    coord_list = sorted(set(x for x in endpoints))
-    counts_between = {}
-    ev_idx = 0
-    evn = len(events)
-    for i in range(len(coord_list)):
-        x = coord_list[i]
-        # process all events at x (with -1 before +1 done by events sort)
-        while ev_idx < evn and events[ev_idx][0] == x:
-            cur += events[ev_idx][1]
-            ev_idx += 1
-        # coverage on (x, next_x) is cur (but if there is no next, ignore)
-        if i+1 < len(coord_list):
-            counts_between[(coord_list[i], coord_list[i+1])] = cur
-    # produce coords and seg_counts list in same order
-    coords = coord_list
-    seg_counts = [counts_between[(coords[i], coords[i+1])] for i in range(len(coords)-1)]
-    return coords, seg_counts
-
-def try_add_wave(cur_intervals, target_omega, wave_length=2, candidates_limit=600):
-    """
-    Try to add short "wave" intervals (of integer length wave_length) to increase FirstFit colors
-    without increasing clique number above target_omega.
-
-    Strategy:
-      - enumerate a set of candidate left endpoints chosen between unique endpoints of current intervals
-      - for each candidate construct interval (x, x+wave_length)
-      - accept the first candidate that increases FirstFit color count while keeping omega <= target_omega
-    Returns:
-      - (accepted_interval or None, new_intervals)
-    """
-    # Work on normalized integer intervals
-    T = list(cur_intervals)
-    if not T:
-        return None, T
-    coords = sorted(set(x for iv in T for x in iv))
-    # generate candidate left positions: between coords[i], coords[i+1]-wave_length (so interval fits)
-    # to limit candidates, sample uniformly across range as well as near dense regions
-    min_x = min(coords)
-    max_x = max(coords)
-    # candidate lefts: use endpoints and midpoints of large gaps
-    left_candidates = set()
-    for a,b in zip(coords, coords[1:]):
-        # try left placements anchored near a, near midpoint, and near b-wave_length
-        if b - a <= 0:
-            continue
-        # choose up to three placements in this gap if it can host wave_length
-        if b - a >= wave_length + 1:
-            left_candidates.add(a + 1)
-            left_candidates.add((a + b) // 2)
-            left_candidates.add(b - wave_length - 1)
-        else:
-            left_candidates.add(a)
-    # also sample a small grid across whole range
-    step = max(1, (max_x - min_x) // 30)
-    for x in range(min_x, max_x - wave_length + 1, step):
-        left_candidates.add(x)
-    # cap candidates
-    lefts = sorted(left_candidates)
-    if len(lefts) > candidates_limit:
-        # downsample deterministically
-        lefts = [lefts[i] for i in range(0, len(lefts), max(1, len(lefts)//candidates_limit))]
-
-    base_cols = firstfit_colors(T)
-    base_om = clique_number(T)
-    # quick reject if base_om already exceeds target
-    if base_om > target_omega:
-        target_omega = base_om
-
-    for x in lefts:
-        cand = (x, x + wave_length)
-        # don't add degenerate or overlapping with endpoints equalities only (open intervals)
-        if cand[0] >= cand[1]:
-            continue
-        # ensure clique remains <= target_omega
-        new_om = clique_number(T + [cand])
-        if new_om > target_omega:
-            continue
-        # compute FirstFit colors on the augmented sequence (append at the end)
-        new_cols = firstfit_colors(T + [cand])
-        if new_cols > base_cols:
-            # accept
-            T2 = T + [cand]
-            return cand, T2
-    return None, T
-
-# ---------- Conservative pruning to keep instance compact ----------
-
-def conservative_prune(intervals, keep_ratio):
-    """
-    Try removing intervals one-by-one (prefer long ones) while preserving observed FirstFit/OPT ratio >= keep_ratio.
-    Deterministic greedy pass.
+# ---------- Deterministic frontier-preserving pruning ----------
+
+def prune_preserve_colors_and_omega(intervals):
+    """
+    Remove intervals if and only if both FirstFit colors and omega remain identical.
+    Greedy deterministic pass, removing longer intervals first.
     """
     cur = list(intervals)
     if not cur:
         return cur
-    # compute base observed ratio
-    aux_norm = normalize_to_grid(cur)
-    base_cols = firstfit_colors(aux_norm)
-    base_om = clique_number(aux_norm) or 1
-    base_ratio = base_cols / base_om
-    # only prune if base_ratio >= keep_ratio (it should be)
-    target = keep_ratio if keep_ratio is not None else base_ratio
-
-    def length(iv):
-        return iv[1] - iv[0]
-    # greedy remove longest intervals first
+    base_cols = firstfit_colors(cur)
+    base_om = clique_number(cur)
+    def length(iv): return iv[1] - iv[0]
     changed = True
     while changed:
         changed = False
         order = sorted(range(len(cur)), key=lambda i: (-length(cur[i]), i))
-        for idx in order:
-            cand = cur[:idx] + cur[idx+1:]
-            cand_norm = normalize_to_grid(cand)
-            if not cand_norm:
+        for i in order:
+            cand = cur[:i] + cur[i+1:]
+            if not cand:
                 continue
-            c = firstfit_colors(cand_norm)
-            o = clique_number(cand_norm)
-            if o == 0:
-                continue
-            if (c / o) >= target - 1e-12:
+            c = firstfit_colors(cand)
+            o = clique_number(cand)
+            if c == base_cols and o == base_om:
                 cur = cand
                 changed = True
                 break
     return cur
 
-# ---------- High-level construction + augmentation search ----------
+# ---------- Search space enumerator and selector ----------
 
 def construct_intervals():
     """
-    Build intervals (in arrival order) and attempt to augment them with waves to
-    increase FirstFit color usage while keeping omega controlled.
-
-    Returns normalized integer intervals.
-    """
-    # base seeds and templates to try
-    base_seeds = [
-        [(0.0, 1.0)],                      # canonical single seed
-        [(0.0, 1.0), (2.0, 3.0)],          # two disjoint seeds
+    Enumerate a deterministic family of blueprints (depth/offsets/blockers/schedule/normalization),
+    select the one that maximizes FirstFit/omega, tie-breaking by fewer intervals and then
+    by larger FirstFit colors. Finally prune deterministically while preserving the frontier.
+    """
+    # Offsets sets (four-copy placements)
+    offset_sets = [
+        (2, 6, 10, 14),   # A
+        (1, 5, 9, 13),    # B
+        (3, 7, 11, 15),   # C
+        (0, 4, 8, 12),    # D
     ]
-    depths = [3, 4]  # try a couple of depths (keeps sizes manageable)
-    offset_templates = [
-        (2,6,10,14),    # canonical
-        (1,5,9,13),     # alternative
+
+    # Blocker templates (four connectors)
+    blocker_sets = [
+        ((1, 5), (12, 16), (4, 9), (8, 13)),    # Template A (canonical)
+        ((0, 4), (11, 15), (3, 8), (7, 12)),    # Template B
+        ((1, 5), (9, 13), (5, 9), (12, 16)),    # Template C (shifted pairs)
     ]
-    blocker_templates = [
-        ((1,5),(12,16),(4,9),(8,13)),  # canonical
-        ((0,4),(11,15),(3,8),(7,12)),  # variant
-    ]
+
+    depths = [3, 4, 5]
+    schedules = ['after', 'before', 'split']
+    normalize_policies = ['final', 'each', 'every2']  # 'none' tends to grow footprint; keep compact
     extra_first_choices = [False, True]
 
-    # Evaluate baseline candidates and pick the best one by FF/OPT ratio
-    best = None  # tuple (ratio, cols, om, intervals_raw)
-    for base in base_seeds:
-        for depth in depths:
-            for offs in offset_templates:
-                for blks in blocker_templates:
-                    for extra in extra_first_choices:
-                        T = build_recursive_pattern(base_seed=base, depth=depth, offsets=offs, blockers=blks, extra_first=extra)
-                        Tn = normalize_to_grid(T)
-                        if not Tn:
-                            continue
-                        om = clique_number(Tn)
-                        if om == 0:
-                            continue
-                        cols = firstfit_colors(Tn)
-                        ratio = cols / om
-                        cand = (ratio, cols, om, T)
-                        if best is None or cand[0] > best[0] + 1e-12 or (abs(cand[0]-best[0])<=1e-12 and len(T) < len(best[3])):
-                            best = cand
-
-    if best is None:
-        # fallback: simple canonical depth=4
-        T = build_recursive_pattern([(0.0,1.0)], depth=4)
-    else:
-        T = best[3]
-
-    # Normalize to integer grid for augmentation steps
-    current = normalize_to_grid(T)
-    current_om = clique_number(current)
-    current_cols = firstfit_colors(current)
-    best_ratio = current_cols / current_om if current_om > 0 else 0
-
-    # Augmentation loop: try to add up to max_waves that improve colors while preserving omega
-    max_waves = 60  # keep moderate
-    wave_length = max(1, max(1, max((r-l) for l,r in current)) // 30)  # choose a small wave length relative to scale
-    # ensure wave_length at least 2 for stability if space allows
-    wave_length = max(1, min(3, wave_length))
-    added_any = True
-    waves_added = 0
-    # We'll accept only additions that strictly increase FF colors and keep omega unchanged (or <= original)
-    target_omega = current_om
-    while waves_added < max_waves and added_any:
-        added_any = False
-        cand, newT = try_add_wave(current, target_omega, wave_length=wave_length, candidates_limit=800)
-        if cand is not None:
-            # Update current
-            current = normalize_to_grid(newT)
-            new_om = clique_number(current)
-            new_cols = firstfit_colors(current)
-            if new_om <= target_omega and new_cols > current_cols:
-                current_cols = new_cols
-                current_om = new_om
-                best_ratio = current_cols / current_om if current_om > 0 else best_ratio
-                waves_added += 1
-                added_any = True
-            else:
-                # revert (shouldn't happen given try_add_wave guard) but keep safe
-                # if candidate didn't help, stop to keep deterministic behavior
-                break
-
-    # After augmentation, perform conservative pruning while preserving observed ratio
-    observed_ratio = current_cols / current_om if current_om > 0 else best_ratio
-    pruned = conservative_prune(current, observed_ratio)
-    final_norm = normalize_to_grid(pruned)
-    # final sanity: ensure we didn't lose the ratio through pruning; if so, return pre-prune
-    if final_norm:
-        final_cols = firstfit_colors(final_norm)
-        final_om = clique_number(final_norm) or 1
-        if final_cols / final_om + 1e-12 < observed_ratio:
-            return current  # return pre-prune normalized
-        else:
-            return final_norm
-    else:
-        return current
+    best_T = None
+    best_ratio = -1.0
+    best_n = None
+    best_cols = -1
+    best_om = 1
+
+    for k in depths:
+        for offs in offset_sets:
+            for blks in blocker_sets:
+                for sch in schedules:
+                    for normp in normalize_policies:
+                        for ex in extra_first_choices:
+                            T = build_pattern(
+                                depth=k,
+                                offsets=offs,
+                                blockers=blks,
+                                schedule=sch,
+                                add_extra_first=ex,
+                                normalize_schedule=normp
+                            )
+                            if not T:
+                                continue
+                            om = clique_number(T)
+                            if om == 0:
+                                continue
+                            cols = firstfit_colors(T)
+                            ratio = cols / om
+                            n = len(T)
+                            better = False
+                            if ratio > best_ratio + 1e-12:
+                                better = True
+                            elif abs(ratio - best_ratio) <= 1e-12:
+                                if best_n is None or n < best_n - 0:
+                                    better = True
+                                elif n == best_n and cols > best_cols:
+                                    better = True
+                            if better:
+                                best_ratio = ratio
+                                best_T = T
+                                best_n = n
+                                best_cols = cols
+                                best_om = om
+
+    # Fallback to canonical if search fails (should not happen)
+    if best_T is None:
+        best_T = build_pattern(
+            depth=4,
+            offsets=(2, 6, 10, 14),
+            blockers=((1, 5), (12, 16), (4, 9), (8, 13)),
+            schedule='after',
+            add_extra_first=False,
+            normalize_schedule='final'
+        )
+
+    # Deterministic pruning preserving both FF colors and omega
+    pruned = prune_preserve_colors_and_omega(best_T)
+    # Ensure normalization to compact grid and return
+    return normalize_and_reduce_gcd(pruned)
 
 # EVOLVE-BLOCK-END
 
 def run_experiment(**kwargs):
   """Main called by evaluator"""
   return construct_intervals()