# EVOLVE-BLOCK-START

from math import gcd
from functools import reduce

def overlaps(a, b):
    """Open-interval overlap test (l1,r1) with (l2,r2)."""
    (l1, r1), (l2, r2) = a, b
    return max(l1, l2) < min(r1, r2)

def firstfit_colors(intervals):
    """
    FirstFit coloring for the normalized integer intervals.
    Maintains last_end per color; an interval fits if its left endpoint >= last_end[color].
    """
    last_end = []
    for (l, r) in intervals:
        placed = False
        for i in range(len(last_end)):
            if l >= last_end[i]:
                last_end[i] = r
                placed = True
                break
        if not placed:
            last_end.append(r)
    return len(last_end)

def clique_number(intervals):
    """
    Open-interval clique number via sweep line.
    Intervals are assumed open; we count how many intervals cover a point.
    """
    events = []
    for (l, r) in intervals:
        if l >= r:
            continue
        events.append((l, +1))
        events.append((r, -1))
    # For ties, process endings before beginnings
    events.sort(key=lambda e: (e[0], -e[1]))
    cur = 0
    best = 0
    for _, t in events:
        cur += t
        if cur > best:
            best = cur
    return best

def normalize_intervals(intervals):
    """
    Normalize coordinates to a compact integer grid.
    - Multiply by 2 to handle halves
    - Map unique endpoints to increasing integers
    - Shift to start at 0
    - Divide by gcd to shrink
    Returns a list of normalized (l,r) with integer endpoints.
    """
    if not intervals:
        return []
    scaled = []
    for (l, r) in intervals:
        L = int(round(l * 2))
        R = int(round(r * 2))
        scaled.append((L, R))
    min_coord = min(min(l, r) for l, r in scaled)
    shifted = [(l - min_coord, r - min_coord) for (l, r) in scaled]
    vals = []
    for (l, r) in shifted:
        vals.append(abs(l))
        vals.append(abs(r))
    g = 0
    for v in vals:
        g = gcd(g, v)
    if g > 1:
        return [(l // g, r // g) for (l, r) in shifted]
    else:
        return shifted

def make_copies(T, starts, delta, lo, center, translation):
    """Create translated copies of T according to the selected pattern."""
    S = []
    for start in starts:
        if translation == 'left':
            offset = delta * start - lo
        else:  # 'center'
            offset = delta * start - center
        for (l, r) in T:
            S.append((l + offset, r + offset))
    return S

def add_blockers(S, blockers, delta, anchor, center):
    """Add four blockers, anchored either to left or to center."""
    for (a, b) in blockers:
        if anchor == 'left':
            S.append((delta * a, delta * b))
        else:
            S.append((delta * a - center, delta * b - center))
    return S

def build_pattern(base_seed, k, starts, blockers, translation, blocker_anchor, extra_copies=0):
    """
    Expand base_seed k times using the copy + blocker scheme.
    extra_copies adds a small diversification on the first level.
    """
    T = list(base_seed)
    for level in range(k):
        lo = min(l for l, r in T)
        hi = max(r for l, r in T)
        delta = hi - lo
        center = (lo + hi) / 2.0

        offs = list(starts)
        if level == 0 and extra_copies > 0:
            last = offs[-1] if offs else 0
            for t in range(extra_copies):
                offs.append(last + 4 * (t + 1))

        S = make_copies(T, offs, delta, lo, center, translation)
        S = add_blockers(S, blockers, delta, blocker_anchor, center)
        T = S
    return T

def evaluate_with_raw(intervals):
    """Return (score, omega, colors, n, normalized, raw)."""
    Tn = normalize_intervals(intervals)
    n = len(Tn)
    if n == 0:
        return (-1.0, 0, 0, n, Tn, intervals)
    om = clique_number(Tn)
    if om == 0:
        return (-1.0, 0, 0, n, Tn, intervals)
    cols = firstfit_colors(Tn)
    ratio = cols / om if om > 0 else 0.0
    score = ratio - 1e-6 * (n / 10000.0)
    return (score, om, cols, n, Tn, intervals)

def shrink_intervals(intervals, max_trials=5000):
    """
    Greedy removal: try removing intervals from end to start; keep a witness if
    omega and colors do not decrease.
    """
    T = list(intervals)
    base_score, base_om, base_cols, _, _ = evaluate_with_raw(T)
    if len(T) <= 8:
        return T
    i = 0
    trials = 0
    while trials < max_trials and i < len(T):
        idx = len(T) - 1 - i
        trials += 1
        cand = T[:idx] + T[idx+1:]
        s, om, cols, n, _, _ = evaluate_with_raw(cand)
        if om == base_om and cols >= base_cols:
            T = cand
            base_cols = cols
            base_score = s
            i = 0
            continue
        i += 1
    return T

def construct_intervals(iterations=4):
  """
  Diversified parametric witness constructor.
  Builds a set of candidate interval sequences and selects the best
  according to the evaluation metric (FF colors / clique size) with
  a small penalty for larger witness size.
  """
  # Pattern pools (diversify tiling)
  start_patterns = [
      (2, 6, 10, 14),
      (1, 5, 9, 13),
      (3, 7, 11, 15),
      (0, 4, 8, 12),
  ]
  blocker_templates = [
      [(1, 5), (12, 16), (4, 9), (8, 13)],   # A
      [(0, 4), (11, 15), (3, 8), (7, 12)],   # B
      [(2, 6), (4, 8), (10, 14), (12, 16)],  # C
      [(1, 6), (7, 11), (9, 13), (14, 19)],  # D
  ]
  translations = ['left', 'center']
  blocker_anchors = ['left', 'center']
  extra_choices = [0, 1]
  base_seeds = [
      [(0.0, 1.0)],
      [(0.0, 1.0), (2.0, 3.0)]
  ]

  MAX_INTERVALS = 2000
  best = None  # (score, om, cols, n, Tn, raw)

  # Enumerate a diverse set of configurations
  for seed in base_seeds:
    for k in (3, 4, 5):  # exploration over depths
      for starts in start_patterns:
        for blockers in blocker_templates:
          for translation in translations:
            for anchor in blocker_anchors:
              for extra in extra_choices:
                T = build_pattern(
                    base_seed=seed,
                    k=k,
                    starts=starts,
                    blockers=blockers,
                    translation=translation,
                    blocker_anchor=anchor,
                    extra_copies=extra,
                )
                if len(T) > MAX_INTERVALS:
                    continue
                cand = evaluate_with_raw(T)
                if best is None:
                    best = cand
                else:
                    if cand[0] > best[0] + 1e-9:
                        best = cand
                    elif abs(cand[0] - best[0]) <= 1e-9:
                        if cand[3] < best[3]:
                            best = cand
                        elif cand[3] == best[3] and cand[2] > best[2]:
                            best = cand

  # Fallback: if nothing found (extremely unlikely), use a canonical baseline
  if best is None:
    T = [
      (0.0, 1.0),
      (2.0, 3.0)
    ]
    k = 4
    lo = min(l for l, r in T)
    hi = max(r for l, r in T)
    delta = hi - lo
    S = []
    for start in (2, 6, 10, 14):
      offset = delta * start - lo
      S.extend([(offset + l, offset + r) for l, r in T])
    S += [
      (delta * 1, delta * 5),
      (delta * 12, delta * 16),
      (delta * 4, delta * 9),
      (delta * 8, delta * 13)
    ]
    best = evaluate_with_raw(S)

  raw_best = best[4]  # Tn
  # Shrink the raw witness to prune intervals while preserving witness quality
  shrunk = shrink_intervals(raw_best, max_trials=3000)
  final = normalize_intervals(shrunk)
  if not final:
    # If shrink produced nothing, fallback to normalized raw witness
    final = normalize_intervals(raw_best)
  return final

# EVOLVE-BLOCK-END